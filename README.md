# Задание №1

<h2>Задача 1.1</h2>

Разработать ETL-процесс для загрузки «банковских» данных из csv-файлов в соответствующие таблицы СУБД PostgreSQL. Покрыть данный процесс логированием этапов работы и всевозможной дополнительной статистикой (на ваше усмотрение). Обратите внимание, что в разных файлах может быть разный формат даты, это необходимо учитывать при загрузке.

**Требования к реализации задачи:
+ В своей БД создать пользователя / схему «DS».
+ Создать в DS-схеме таблицы под загрузку данных из csv-файлов.
+ Начало и окончание работы процесса загрузки данных должно логироваться в специальную логовую таблицу. Эту таблицу нужно придумать самостоятельно. По логам должно быть видно дату и время старта и окончания загрузки, так же можете туда добавить любую дополнительную информацию, которую посчитаете нужным.
+ После логирования о начале загрузки добавить таймер (паузу) на 5 секунд, чтобы чётко видеть разницу во времени между началом и окончанием загрузки. Из-за небольшого учебного объёма данных – процесс загрузки быстрый;
+ Для хранения логов нужно в БД создать отдельного пользователя / схему «LOGS» и создать в этой схеме таблицу для логов;
+ Для корректного обновления данных в таблицах детального слоя DS нужно выбрать правильную Update strategy и использовать следующие первичные ключи для таблиц фактов, измерений и справочников (должно быть однозначное уникальное значение, идентифицирующее каждую запись таблицы):
Таблица


**Решение:
 1. Подготовить sql скрипты для создания схем и таблиц
2. реализовать логику по загрузки данных о логирование в таблицу с логами
3. релизовать методы для корректного добовления данных в бд и их обновления



Запуск проекта

Из корневой папки выполняем команду:

```
docker-compose up
```

Ссылка на видо с демонстрацией <a href="https://disk.yandex.ru/i/SKjWxkwKqzAP8g">тут</a>
