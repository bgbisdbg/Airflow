# Задание №1

## Задача 1.1

Разработать ETL-процесс для загрузки «банковских» данных из csv-файлов в соответствующие таблицы СУБД PostgreSQL. Покрыть данный процесс логированием этапов работы и всевозможной дополнительной статистикой (на ваше усмотрение). Обратите внимание, что в разных файлах может быть разный формат даты, это необходимо учитывать при загрузке.

### Требования к реализации задачи:

- В своей БД создать пользователя / схему «DS».
- Создать в DS-схеме таблицы под загрузку данных из csv-файлов.
- Начало и окончание работы процесса загрузки данных должно логироваться в специальную логовую таблицу. Эту таблицу нужно придумать самостоятельно. По логам должно быть видно дату и время старта и окончания загрузки, так же можете туда добавить любую дополнительную информацию, которую посчитаете нужным.
- После логирования о начале загрузки добавить таймер (паузу) на 5 секунд, чтобы чётко видеть разницу во времени между началом и окончанием загрузки. Из-за небольшого учебного объёма данных – процесс загрузки быстрый.
- Для хранения логов нужно в БД создать отдельного пользователя / схему «LOGS» и создать в этой схеме таблицу для логов.
- Для корректного обновления данных в таблицах детального слоя DS нужно выбрать правильную Update strategy и использовать следующие первичные ключи для таблиц фактов, измерений и справочников (должно быть однозначное уникальное значение, идентифицирующее каждую запись таблицы).

### Решение:

1. Подготовить SQL-скрипты для создания схем и таблиц.
2. Реализовать логику по загрузке данных и логированию в таблицу с логами.
3. Реализовать методы для корректного добавления данных в БД и их обновления.

### Запуск проекта

Из корневой папки выполняем команду:

```bash
docker-compose up
```

Ссылка на видо с демонстрацией <a href="https://disk.yandex.ru/i/SKjWxkwKqzAP8g">тут</a>
